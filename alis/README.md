# ğŸ” ALIS - Aadhaar Lifecycle Intelligence System

> **AI-Powered Risk Analytics for UIDAI** | UIDAI Hackathon 2026

![Python](https://img.shields.io/badge/Python-3.12-blue?logo=python)
![FastAPI](https://img.shields.io/badge/FastAPI-0.109-009688?logo=fastapi)
![Streamlit](https://img.shields.io/badge/Streamlit-1.31-FF4B4B?logo=streamlit)
![License](https://img.shields.io/badge/License-MIT-green)

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Architecture](#-architecture)
- [Quick Start](#-quick-start)
- [Data Pipeline](#-data-pipeline)
- [ML Models](#-ml-models)
- [API Documentation](#-api-documentation)
- [Dashboard Guide](#-dashboard-guide)
- [Project Structure](#-project-structure)
- [Configuration](#-configuration)
- [Contributing](#-contributing)

---

## ğŸ¯ Overview

**ALIS** (Aadhaar Lifecycle Intelligence System) is an advanced analytics platform designed to help UIDAI monitor, predict, and optimize Aadhaar update operations across India.

### The Problem

- **Fraud Detection**: Identify unusual biometric/demographic update patterns
- **Resource Planning**: Predict enrollment center demand 30 days in advance
- **Risk Prioritization**: Focus limited resources on high-risk areas
- **Operational Efficiency**: Reduce wastage in kit deployment

### The Solution

ALIS provides:
- ğŸ”´ **Real-time Risk Scoring** across 19,815 pincodes
- ğŸ“Š **ML-powered Forecasting** using SARIMA + XGBoost ensemble
- ğŸ—ºï¸ **Geographic Visualization** with interactive maps
- âš ï¸ **Anomaly Detection** using Isolation Forest
- ğŸ¯ **K-Means Clustering** for strategic segmentation

---

## âœ¨ Features

| Feature | Description | Technology |
|---------|-------------|------------|
| **Risk Scoring** | Multi-factor risk calculation (Bio, Demo, Mobile) | Custom Algorithm |
| **Forecasting** | 30-day bio/demo update predictions | SARIMA + XGBoost |
| **Clustering** | Auto-segmentation into 7 risk clusters | K-Means |
| **Anomaly Detection** | Spike/Drop detection using multiple methods | Isolation Forest |
| **Interactive Dashboard** | 6 pages with visualizations | Streamlit + Plotly |
| **REST API** | Full CRUD operations + ML endpoints | FastAPI |
| **Geographic Maps** | State-wise and pincode-level mapping | Plotly Mapbox |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ALIS                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   Streamlit  â”‚  â”‚   FastAPI    â”‚  â”‚   SQLite     â”‚          â”‚
â”‚  â”‚  Dashboard   â”‚â”€â”€â”‚   Backend    â”‚â”€â”€â”‚   Database   â”‚          â”‚
â”‚  â”‚  :8501       â”‚  â”‚  :8000       â”‚  â”‚              â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â”‚                  â”‚                                     â”‚
â”‚         â–¼                  â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚            ML Pipeline                   â”‚                    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚                    â”‚
â”‚  â”‚  â”‚ SARIMA  â”‚ â”‚ XGBoost â”‚ â”‚ K-Means â”‚   â”‚                    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚                    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚                    â”‚
â”‚  â”‚  â”‚ Isolation Forest  â”‚                  â”‚                    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.12+
- pip (Python package manager)

### Installation

```bash
# 1. Clone the repository
git clone https://github.com/your-username/alis.git
cd alis

# 2. Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# 3. Install dependencies
pip install -r backend/requirements.txt

# 4. Place your CSV data files in:
#    backend/data/raw/api_data_aadhar_biometric/
#    backend/data/raw/api_data_aadhar_demographic/
#    backend/data/raw/api_data_aadhar_enrolment/
```

### Running ALIS

```bash
# Full pipeline (recommended for first run)
python app.py

# Quick start (skip data loading, use existing data)
python app.py --quick

# Dashboard only (after models are trained)
python app.py --dashboard-only

# Train models only (no server)
python app.py --train-only
```

### Access Points

| Service | URL | Description |
|---------|-----|-------------|
| **Dashboard** | http://localhost:8501 | Streamlit Analytics |
| **API** | http://localhost:8000 | FastAPI Backend |
| **API Docs** | http://localhost:8000/api/docs | Swagger UI |
| **Landing Page** | http://localhost:3000 | Project Overview |

---

## ğŸ“Š Data Pipeline

### Data Sources

ALIS processes three types of Aadhaar update data:

1. **Biometric Updates** (`api_data_aadhar_biometric/`)
   - Fingerprint, Iris updates by age group
   - ~1.86M records

2. **Demographic Updates** (`api_data_aadhar_demographic/`)
   - Name, Address, DOB changes
   - ~2.07M records

3. **Enrollment Data** (`api_data_aadhar_enrolment/`)
   - New Aadhaar registrations
   - ~1.0M records

### Processing Steps

```
CSV Files â†’ Data Ingestion â†’ Merge & Clean â†’ Risk Calculation â†’ ML Training
                                                      â†“
                                              Risk Metrics (19,815 pincodes)
                                              Clusters (7 groups)
                                              Anomalies (376 detected)
                                              Forecasts (SARIMA + XGBoost)
```

---

## ğŸ§  ML Models

### 1. Risk Scoring Engine

**Components:**
- Bio Risk Score (35% weight)
- Demo Risk Score (25% weight)
- Mobile Linkage Gap (20% weight)
- Migration Score (10% weight)
- Volatility Score (10% weight)

**Categories:**
- ğŸ”´ **CRITICAL** (80-100): Immediate investigation
- ğŸŸ  **HIGH** (60-79): Close monitoring
- ğŸŸ¡ **MEDIUM** (40-59): Periodic review
- ğŸŸ¢ **LOW** (0-39): Normal operation

### 2. Forecasting (SARIMA + XGBoost)

**SARIMA** (Seasonal ARIMA):
- Captures trends and seasonality
- Auto-optimizes (p,d,q) parameters
- AIC-based model selection

**XGBoost**:
- Gradient boosted trees
- Lag features (7, 14, 30 days)
- Rolling statistics

**Ensemble**: Weighted average of both models

### 3. K-Means Clustering

**Cluster Profiles:**
- `HIGH_RISK`: Immediate attention areas
- `HIGH_MIGRATION_URBAN`: Urban areas with high mobility
- `CHILD_FOCUS`: Schools/educational zones
- `STABLE_RURAL`: Low-activity rural areas
- `GROWING`: Developing regions

### 4. Anomaly Detection

**Methods:**
- Z-Score (statistical)
- IQR (robust)
- Isolation Forest (ML)

**Consensus**: Flags anomaly when 2+ methods agree

---

## ğŸ”Œ API Documentation

### Endpoints Overview

```
GET  /api/v1/pincodes/          # List all pincodes
GET  /api/v1/pincodes/{pincode} # Get pincode details
POST /api/v1/pincodes/calculate # Recalculate metrics

GET  /api/v1/predictions/       # List predictions
POST /api/v1/predictions/       # Generate forecast

GET  /api/v1/anomalies/         # List anomalies
GET  /api/v1/clusters/          # List clusters
GET  /api/v1/recommendations/   # Get recommendations
```

### Example: Get Pincode Risk

```bash
curl http://localhost:8000/api/v1/pincodes/110001
```

Response:
```json
{
  "pincode": "110001",
  "state": "Delhi",
  "bio_risk_score": 75.2,
  "overall_risk_score": 82.5,
  "risk_category": "CRITICAL",
  "cluster_id": 3
}
```

---

## ğŸ“ˆ Dashboard Guide

### Navigation

| Page | Purpose |
|------|---------|
| **ğŸ  Home & Tutorial** | Step-by-step guide for new users |
| **ğŸ“Š Dashboard** | KPIs, Risk Distribution, Trends |
| **ğŸ—ºï¸ Map View** | Geographic visualization |
| **ğŸ“ˆ Analytics** | Correlation, Clusters, Distributions |
| **ğŸ§  Model Evaluation** | MAE, RMSE, AIC metrics |
| **âš ï¸ Anomalies** | Detected spikes and drops |
| **ğŸ”® Predictions** | Generate forecasts |

### Tutorial Mode

Enable/disable tutorial hints via the sidebar checkbox:
`â˜‘ï¸ Show Tutorial`

---

## ğŸ“ Project Structure

```
alis/
â”œâ”€â”€ app.py                 # ğŸš€ Main entry point
â”œâ”€â”€ streamlit_app.py       # ğŸ“Š Streamlit dashboard
â”œâ”€â”€ run.py                 # Alternative launcher
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py        # FastAPI application
â”‚   â”‚   â”œâ”€â”€ config.py      # Configuration
â”‚   â”‚   â”œâ”€â”€ database.py    # SQLAlchemy setup
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ db_models.py   # Database models
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”‚   â”œâ”€â”€ pincodes.py
â”‚   â”‚   â”‚   â”œâ”€â”€ predictions.py
â”‚   â”‚   â”‚   â”œâ”€â”€ anomalies.py
â”‚   â”‚   â”‚   â””â”€â”€ clusters.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ risk_calculator.py
â”‚   â”‚   â”‚   â”œâ”€â”€ forecaster.py
â”‚   â”‚   â”‚   â”œâ”€â”€ clustering.py
â”‚   â”‚   â”‚   â”œâ”€â”€ anamoly_detector.py
â”‚   â”‚   â”‚   â””â”€â”€ data_ingestion.py
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ ml/
â”‚   â”‚       â”œâ”€â”€ sarima_model.py
â”‚   â”‚       â”œâ”€â”€ xgboost_model.py
â”‚   â”‚       â”œâ”€â”€ ensemble.py
â”‚   â”‚       â””â”€â”€ train_models.py
â”‚   â”‚
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ raw/           # CSV source files (gitignored)
â”‚   â”‚   â””â”€â”€ models/        # Trained model files
â”‚   â”‚
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env               # Environment variables
â”‚
â”œâ”€â”€ Frontend/
â”‚   â””â”€â”€ index.html         # Landing page
â”‚
â””â”€â”€ scripts/
    â”œâ”€â”€ load_csv_data.py   # CSV data loader
    â”œâ”€â”€ train_all_models.py
    â””â”€â”€ clear_data.py
```

---

## âš™ï¸ Configuration

### Environment Variables

Create `backend/.env`:

```env
# Database
DATABASE_URL=sqlite:///./data/alis.db

# API Settings
API_HOST=0.0.0.0
API_PORT=8000

# ML Settings
MODEL_DIR=./data/models
TRAINING_SAMPLES=90
```

### Key Settings (`backend/app/config.py`)

| Setting | Default | Description |
|---------|---------|-------------|
| `RISK_CRITICAL_THRESHOLD` | 80 | Score for critical risk |
| `RISK_HIGH_THRESHOLD` | 60 | Score for high risk |
| `DEFAULT_CLUSTERS` | 5 | K-Means clusters |
| `FORECAST_HORIZON` | 30 | Days to forecast |

---

## ğŸ“Š Performance Metrics

| Metric | Value |
|--------|-------|
| Pincodes Analyzed | 19,815 |
| Records Processed | 3.7M+ |
| Model Accuracy | 87% |
| Risk Clusters | 7 |
| Anomalies Detected | 376 |
| API Response Time | <200ms |

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/new-feature`
3. Commit changes: `git commit -m 'Add new feature'`
4. Push to branch: `git push origin feature/new-feature`
5. Create Pull Request

---

## ğŸ“œ License

This project was developed for **UIDAI Hackathon 2026**.

MIT License - See [LICENSE](LICENSE) for details.

---

## ğŸ‘¥ Team

**ALIS Team** - UIDAI Hackathon 2026

---

<p align="center">
  <strong>ğŸ” ALIS - Securing India's Digital Identity</strong><br>
  Built with â¤ï¸ for Digital India
</p>

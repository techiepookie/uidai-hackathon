# ALIS - Aadhaar Lifecycle Intelligence System

<p align="center">
  <img src="https://img.shields.io/badge/version-4.0.0-blue.svg" alt="Version">
  <img src="https://img.shields.io/badge/python-3.12-green.svg" alt="Python">
  <img src="https://img.shields.io/badge/license-MIT-orange.svg" alt="License">
</p>

**ALIS** is a predictive intelligence system for Aadhaar lifecycle management. It transforms raw update data into actionable operational intelligence to optimize resource allocation and reduce authentication failures.

## ğŸš€ Features

- **Risk Scoring**: 8 risk metrics with priority scoring and categorization (LOW, MEDIUM, HIGH, CRITICAL)
- **Anomaly Detection**: Multi-method detection (Z-Score, IQR, Isolation Forest, Rolling Statistics)
- **Forecasting**: Ensemble model combining SARIMA and XGBoost for 30-90 day predictions
- **Clustering**: K-means segmentation of pincodes into operational profiles
- **Real-time Dashboard**: Interactive visualization with India map, charts, and priority tables
- **REST API**: Comprehensive FastAPI backend with 30+ endpoints

## ğŸ“‹ Quick Start

### Prerequisites
- Python 3.12+
- Node.js (optional, for frontend development)
- Docker & Docker Compose (recommended)

### Option 1: Docker (Recommended)

```bash
# Clone and navigate
cd alis

# Start all services
docker-compose up -d

# Access the dashboard
open http://localhost
```

### Option 2: Local Development

```bash
# Backend setup
cd backend
pip install -r requirements.txt

# Initialize database and generate sample data
cd ../scripts
python init_db.py
python generate_sample_data.py --pincodes 100 --days 90
python load_data.py
python train_all_models.py

# Start API server
cd ../backend
uvicorn app.main:app --reload --port 8000

# Open frontend (separate terminal)
# Simply open Frontend/index.html in a browser
# Or use a local server:
cd ../Frontend
python -m http.server 3000
```

## ğŸ“ Project Structure

```
alis/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ ml/               # Machine learning models
â”‚   â”‚   â”‚   â”œâ”€â”€ ensemble.py   # Ensemble forecaster
â”‚   â”‚   â”‚   â”œâ”€â”€ sarima_model.py
â”‚   â”‚   â”‚   â”œâ”€â”€ xgboost_model.py
â”‚   â”‚   â”‚   â””â”€â”€ train_models.py
â”‚   â”‚   â”œâ”€â”€ models/           # Database & API models
â”‚   â”‚   â”‚   â”œâ”€â”€ db_models.py  # SQLAlchemy ORM
â”‚   â”‚   â”‚   â””â”€â”€ schemas.py    # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ routers/          # API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ pincodes.py   # Pincode data
â”‚   â”‚   â”‚   â”œâ”€â”€ analytics.py  # Dashboard stats
â”‚   â”‚   â”‚   â”œâ”€â”€ predictions.py
â”‚   â”‚   â”‚   â””â”€â”€ anomalies.py
â”‚   â”‚   â”œâ”€â”€ services/         # Business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ risk_calculator.py
â”‚   â”‚   â”‚   â”œâ”€â”€ anamoly_detector.py
â”‚   â”‚   â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â”‚   â”‚   â”œâ”€â”€ forecaster.py
â”‚   â”‚   â”‚   â””â”€â”€ clustering.py
â”‚   â”‚   â”œâ”€â”€ config.py         # Settings
â”‚   â”‚   â”œâ”€â”€ database.py       # DB connection
â”‚   â”‚   â””â”€â”€ main.py           # FastAPI app
â”‚   â”œâ”€â”€ data/                 # Data storage
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ Frontend/
â”‚   â”œâ”€â”€ css/style.css         # Dark theme styles
â”‚   â”œâ”€â”€ js/
â”‚   â”‚   â”œâ”€â”€ app.js            # Main application
â”‚   â”‚   â”œâ”€â”€ api.js            # API client
â”‚   â”‚   â”œâ”€â”€ charts.js         # Chart.js
â”‚   â”‚   â”œâ”€â”€ map.js            # Leaflet map
â”‚   â”‚   â””â”€â”€ tables.js         # Data tables
â”‚   â””â”€â”€ index.html            # Dashboard
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ init_db.py            # Database setup
â”‚   â”œâ”€â”€ generate_sample_data.py
â”‚   â”œâ”€â”€ load_data.py
â”‚   â””â”€â”€ train_all_models.py
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ nginx.conf
â””â”€â”€ README.md
```

## ğŸ”Œ API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/analytics/dashboard-stats` | GET | Dashboard statistics |
| `/api/v1/analytics/state-overview` | GET | State-wise overview |
| `/api/v1/pincodes/` | GET | List all pincodes |
| `/api/v1/pincodes/priority` | GET | Top priority pincodes |
| `/api/v1/pincodes/{pincode}` | GET | Pincode details |
| `/api/v1/pincodes/{pincode}/forecast` | GET | Forecast predictions |
| `/api/v1/anomalies/` | GET | List anomalies |
| `/api/v1/predictions/{pincode}/generate` | POST | Generate forecast |
| `/health` | GET | Health check |

Full API documentation available at `http://localhost:8000/api/docs`

## âš™ï¸ Configuration

Create a `.env` file in the `backend/` directory:

```env
# Database
DATABASE_URL=sqlite:///./data/alis.db

# For PostgreSQL:
# DATABASE_URL=postgresql://user:pass@localhost:5432/alis_db

# Application
DEBUG=true
ENVIRONMENT=development
```

## ğŸ“Š Risk Metrics

| Metric | Description | Weight |
|--------|-------------|--------|
| Child Bio Update Rate | Age 5-17 bio update frequency | High |
| Biometric Intensity | Overall bio update volume | High |
| Mobile Linkage Gap | UnlÃ­nked mobile rate | Medium |
| Demographic Update Rate | Address/demographic changes | Medium |
| Update Volatility | Standard deviation of updates | Low |
| Migration Score | Population movement indicator | Medium |
| Trend Analysis | Directional trend of updates | Medium |
| Overall Risk | Weighted composite score | - |

## ğŸ§ª Testing

```bash
cd backend
pytest tests/ -v --cov=app
```

## ğŸ“ License

MIT License - see [LICENSE](LICENSE) for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

<p align="center">
  Built for UIDAI Hackathon
</p>
